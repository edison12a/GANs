{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2791afc3",
   "metadata": {},
   "source": [
    "# CycleGAN for Monet Paintings Dataset\n",
    "## Kaggle Competition: GAN Getting Started\n",
    "\n",
    "This notebook implements a CycleGAN to translate real-world photos into Monet-style paintings.\n",
    "\n",
    "**Objective:** Convert real-world photographs into Monet-style paintings using Generative Adversarial Networks (GANs), specifically a CycleGAN architecture.\n",
    "\n",
    "**Dataset:**\n",
    "- 300 Monet paintings\n",
    "- 7038 real-world photos\n",
    "\n",
    "The goal is to train a model that learns artistic transformations from Monetâ€™s works and applies them to photographs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abab868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, ReLU, Input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL\n",
    "import shutil\n",
    "from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26722388",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54948c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data path\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "\n",
    "# Get the list of Monet and Photo image files\n",
    "MONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_jpg/*.jpg'))\n",
    "PHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_jpg/*.jpg'))\n",
    "\n",
    "# Print the number of files found\n",
    "print('Monet jpg Files:', len(MONET_FILENAMES))\n",
    "print('Photo jpg Files:', len(PHOTO_FILENAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f829a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f675b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display an example Monet image & Photo image\n",
    "example_monet_path = MONET_FILENAMES[0]\n",
    "monet_image = tf.io.read_file(example_monet_path)\n",
    "monet_image = tf.image.decode_jpeg(monet_image, channels=3)\n",
    "\n",
    "example_photo_path = PHOTO_FILENAMES[0]\n",
    "photo_image = tf.io.read_file(example_photo_path)\n",
    "photo_image = tf.image.decode_jpeg(photo_image, channels=3)\n",
    "\n",
    "# Display the images side by side\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(monet_image.numpy())\n",
    "plt.title(\"Example Monet Image\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(photo_image.numpy())\n",
    "plt.title(\"Example Photo Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d84eb3",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79439897",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [256, 256]\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "def decode_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "monet_ds = tf.data.Dataset.from_tensor_slices(MONET_FILENAMES).map(decode_image).batch(BATCH_SIZE)\n",
    "photo_ds = tf.data.Dataset.from_tensor_slices(PHOTO_FILENAMES).map(decode_image).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca90df",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    inputs = Input(shape=(256, 256, 3))\n",
    "    x = Conv2D(32, (7, 7), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2DTranspose(3, (7, 7), padding='same', activation='tanh')(x)\n",
    "    return keras.Model(inputs, x, name=\"Generator\")\n",
    "\n",
    "def build_discriminator():\n",
    "    inputs = Input(shape=(256, 256, 3))\n",
    "    x = Conv2D(32, (4, 4), strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(1, (4, 4), padding='same')(x)\n",
    "    return keras.Model(inputs, x, name=\"Discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720ca03",
   "metadata": {},
   "source": [
    "## Training the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b19f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan = CycleGAN()\n",
    "cycle_gan.train(photo_ds, monet_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3fb12c",
   "metadata": {},
   "source": [
    "## Results and Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../images\n",
    "\n",
    "i = 1\n",
    "for img in photo_ds:\n",
    "    prediction = cycle_gan.models[\"generator_G\"](img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    im = PIL.Image.fromarray(prediction)\n",
    "    im.save(f\"../images/{i}.jpg\")\n",
    "    i += 1\n",
    "\n",
    "shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667097de",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- We trained a CycleGAN to transform real-world images into Monet-style paintings.\n",
    "- The model successfully generated Monet-style paintings but requires more training for fine details.\n",
    "- Future work includes longer training, better hyperparameter tuning, and possibly using perceptual loss for improved texture reproduction."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
